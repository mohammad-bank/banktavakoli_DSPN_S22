{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2W919d2ZXp7"
   },
   "source": [
    "# Homework 6: Mixed effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L4nOzVhyZXqK"
   },
   "source": [
    "This homework assignment is designed to give you practice fitting and interpreting mixed effects models. \n",
    "\n",
    "We will be using the **LexicalData.csv** and **Items.csv** files from the *Homework/lexDat* folder in the class GitHub repository again. \n",
    "\n",
    "This data is a subset of the [English Lexicon Project database](https://elexicon.wustl.edu/). It provides the reaction times (in milliseconds) of many subjects as they are presented with letter strings and asked to decide, as quickly and as accurately as possible, whether the letter string is a word or not. The **Items.csv** provides characteristics of the words used, namely frequency (how common is this word?) and length (how many letters?). Unlike in the previous homework, there isn't any missing data in the **LexicalData.csv** file. \n",
    "\n",
    "*Data courtesy of Balota, D.A., Yap, M.J., Cortese, M.J., Hutchison, K.A., Kessler, B., Loftis, B., Neely, J.H., Nelson, D.L., Simpson, G.B., & Treiman, R. (2007). The English Lexicon Project. Behavior Research Methods, 39, 445-459.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DsyBTB6ZXqN"
   },
   "source": [
    "---\n",
    "## 1. Loading and formatting the data (1 point)\n",
    "\n",
    "Load in data from the **LexicalData.csv** and **Items.csv** files. As in the previous homeworks, remove the commas from the reaction times and convert them from strings to numbers. Use `left_join` to add word characteristics `Length` and `Log_Freq_Hal` from **Items** to **LexicalData**. \n",
    "\n",
    "*Note: the `Freq_HAL` variable in **Items.csv** has a similar formatting issue, using string values with commas. We're not going to worry about fixing this since we're only using `Log_Freq_HAL`, which is the natural log transformation of `Freq_HAL`, in this homework.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 3646,
     "status": "ok",
     "timestamp": 1615941478718,
     "user": {
      "displayName": "Patience Stevens",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi-_9ZqhIFhAv1oMehJNvNuIKSTyrFQHzjxQKhx=s64",
      "userId": "01994571539255174942"
     },
     "user_tz": 240
    },
    "id": "UnBVazYfZXqP",
    "outputId": "ac15e53d-db29-431a-cefe-c4a81bee3024"
   },
   "outputs": [],
   "source": [
    "setwd(\"~/Downloads\")\n",
    "lexdat = read.csv(\"LexicalData.csv\")\n",
    "items = read.csv(\"Items.csv\")\n",
    "lexdat$D_RT = as.numeric(gsub(',','',lexdat$D_RT))\n",
    "lexdat = lexdat[!is.na(lexdat$D_RT), ]\n",
    "lexdat = lexdat[lexdat$D_RT >= 0, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/3w/m1hxgx4d3g38l_05xm_y1b700000gn/T//RtmphEQJMH/downloaded_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.1 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.5     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.1.6     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.8\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.2.0     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 2.1.2     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.1\n",
      "\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"tidyverse\")\n",
    "library(tidyverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Word</th><th scope=col>Length</th><th scope=col>Log_Freq_HAL</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>synergistic</td><td>11</td><td>5.649</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>synonymous </td><td>10</td><td>6.858</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>syntactical</td><td>11</td><td>4.736</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>synthesis  </td><td> 9</td><td>8.816</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>synthesized</td><td>11</td><td>7.904</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>synthesizer</td><td>11</td><td>7.237</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 3\n",
       "\\begin{tabular}{r|lll}\n",
       "  & Word & Length & Log\\_Freq\\_HAL\\\\\n",
       "  & <chr> & <int> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & synergistic & 11 & 5.649\\\\\n",
       "\t2 & synonymous  & 10 & 6.858\\\\\n",
       "\t3 & syntactical & 11 & 4.736\\\\\n",
       "\t4 & synthesis   &  9 & 8.816\\\\\n",
       "\t5 & synthesized & 11 & 7.904\\\\\n",
       "\t6 & synthesizer & 11 & 7.237\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 3\n",
       "\n",
       "| <!--/--> | Word &lt;chr&gt; | Length &lt;int&gt; | Log_Freq_HAL &lt;dbl&gt; |\n",
       "|---|---|---|---|\n",
       "| 1 | synergistic | 11 | 5.649 |\n",
       "| 2 | synonymous  | 10 | 6.858 |\n",
       "| 3 | syntactical | 11 | 4.736 |\n",
       "| 4 | synthesis   |  9 | 8.816 |\n",
       "| 5 | synthesized | 11 | 7.904 |\n",
       "| 6 | synthesizer | 11 | 7.237 |\n",
       "\n"
      ],
      "text/plain": [
       "  Word        Length Log_Freq_HAL\n",
       "1 synergistic 11     5.649       \n",
       "2 synonymous  10     6.858       \n",
       "3 syntactical 11     4.736       \n",
       "4 synthesis    9     8.816       \n",
       "5 synthesized 11     7.904       \n",
       "6 synthesizer 11     7.237       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22mJoining, by = \"Word\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 9</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Word</th><th scope=col>Length</th><th scope=col>Log_Freq_HAL</th><th scope=col>Sub_ID</th><th scope=col>Trial</th><th scope=col>Type</th><th scope=col>D_RT</th><th scope=col>Outlier</th><th scope=col>D_Zscore</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>synergistic</td><td>11</td><td>5.649</td><td>148</td><td>449</td><td>1</td><td> 776</td><td>false</td><td>0.125</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>synonymous </td><td>10</td><td>6.858</td><td> 20</td><td>146</td><td>1</td><td>1525</td><td>false</td><td>1.235</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>syntactical</td><td>11</td><td>4.736</td><td>162</td><td> 47</td><td>1</td><td>1365</td><td>false</td><td>1.768</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>synthesis  </td><td> 9</td><td>8.816</td><td>155</td><td> 93</td><td>1</td><td> 759</td><td>false</td><td>0.745</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>synthesized</td><td>11</td><td>7.904</td><td> 94</td><td> 49</td><td>1</td><td>2850</td><td>false</td><td>4.134</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>synthesizer</td><td>11</td><td>7.237</td><td>272</td><td>182</td><td>1</td><td>1966</td><td>false</td><td>2.699</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 9\n",
       "\\begin{tabular}{r|lllllllll}\n",
       "  & Word & Length & Log\\_Freq\\_HAL & Sub\\_ID & Trial & Type & D\\_RT & Outlier & D\\_Zscore\\\\\n",
       "  & <chr> & <int> & <dbl> & <int> & <int> & <int> & <dbl> & <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & synergistic & 11 & 5.649 & 148 & 449 & 1 &  776 & false & 0.125\\\\\n",
       "\t2 & synonymous  & 10 & 6.858 &  20 & 146 & 1 & 1525 & false & 1.235\\\\\n",
       "\t3 & syntactical & 11 & 4.736 & 162 &  47 & 1 & 1365 & false & 1.768\\\\\n",
       "\t4 & synthesis   &  9 & 8.816 & 155 &  93 & 1 &  759 & false & 0.745\\\\\n",
       "\t5 & synthesized & 11 & 7.904 &  94 &  49 & 1 & 2850 & false & 4.134\\\\\n",
       "\t6 & synthesizer & 11 & 7.237 & 272 & 182 & 1 & 1966 & false & 2.699\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 9\n",
       "\n",
       "| <!--/--> | Word &lt;chr&gt; | Length &lt;int&gt; | Log_Freq_HAL &lt;dbl&gt; | Sub_ID &lt;int&gt; | Trial &lt;int&gt; | Type &lt;int&gt; | D_RT &lt;dbl&gt; | Outlier &lt;chr&gt; | D_Zscore &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | synergistic | 11 | 5.649 | 148 | 449 | 1 |  776 | false | 0.125 |\n",
       "| 2 | synonymous  | 10 | 6.858 |  20 | 146 | 1 | 1525 | false | 1.235 |\n",
       "| 3 | syntactical | 11 | 4.736 | 162 |  47 | 1 | 1365 | false | 1.768 |\n",
       "| 4 | synthesis   |  9 | 8.816 | 155 |  93 | 1 |  759 | false | 0.745 |\n",
       "| 5 | synthesized | 11 | 7.904 |  94 |  49 | 1 | 2850 | false | 4.134 |\n",
       "| 6 | synthesizer | 11 | 7.237 | 272 | 182 | 1 | 1966 | false | 2.699 |\n",
       "\n"
      ],
      "text/plain": [
       "  Word        Length Log_Freq_HAL Sub_ID Trial Type D_RT Outlier D_Zscore\n",
       "1 synergistic 11     5.649        148    449   1     776 false   0.125   \n",
       "2 synonymous  10     6.858         20    146   1    1525 false   1.235   \n",
       "3 syntactical 11     4.736        162     47   1    1365 false   1.768   \n",
       "4 synthesis    9     8.816        155     93   1     759 false   0.745   \n",
       "5 synthesized 11     7.904         94     49   1    2850 false   4.134   \n",
       "6 synthesizer 11     7.237        272    182   1    1966 false   2.699   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lexdat = rename(lexdat, Word = D_Word)\n",
    "items = items[c(\"Word\",\"Length\",\"Log_Freq_HAL\")]\n",
    "head(items)\n",
    "\n",
    "lexdat = dplyr::left_join(items,lexdat)\n",
    "head(lexdat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bXy81Viishk1"
   },
   "source": [
    "---\n",
    "## 2. Model fitting (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7_gEgkbzFtU"
   },
   "source": [
    "First, fit a linear model with `Log_Freq_HAL` and `Length` as predictors, and `D_RT` as the output. Include an interaction term. Use `summary()` to look at the model output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "executionInfo": {
     "elapsed": 218,
     "status": "ok",
     "timestamp": 1615950762843,
     "user": {
      "displayName": "Patience Stevens",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi-_9ZqhIFhAv1oMehJNvNuIKSTyrFQHzjxQKhx=s64",
      "userId": "01994571539255174942"
     },
     "user_tz": 240
    },
    "id": "OIOIg-GRz4rN",
    "outputId": "34ebc9d5-f7dc-4bc0-bc4a-9ed6b8a38630"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = D_RT ~ Log_Freq_HAL * Length, data = lexdat)\n",
       "\n",
       "Residuals:\n",
       "     Min       1Q   Median       3Q      Max \n",
       "-1118.01  -205.23   -86.95    90.77  3147.07 \n",
       "\n",
       "Coefficients:\n",
       "                    Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)         610.1903    14.6678  41.601  < 2e-16 ***\n",
       "Log_Freq_HAL         -6.0239     1.9678  -3.061  0.00221 ** \n",
       "Length               47.7531     1.6368  29.175  < 2e-16 ***\n",
       "Log_Freq_HAL:Length  -2.9421     0.2348 -12.528  < 2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 359.1 on 62606 degrees of freedom\n",
       "Multiple R-squared:  0.09473,\tAdjusted R-squared:  0.09469 \n",
       "F-statistic:  2184 on 3 and 62606 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "linearmod <- lm(D_RT ~ Log_Freq_HAL * Length, data = lexdat)\n",
    "summary(linearmod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pbeg_JrS3mwU"
   },
   "source": [
    "Now, install `lme4` using `install.packages()` and then load the library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 194755,
     "status": "ok",
     "timestamp": 1615942729586,
     "user": {
      "displayName": "Patience Stevens",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi-_9ZqhIFhAv1oMehJNvNuIKSTyrFQHzjxQKhx=s64",
      "userId": "01994571539255174942"
     },
     "user_tz": 240
    },
    "id": "hFSnvvb_re2O",
    "outputId": "c834867c-929f-4792-ed8f-753f0b17d91a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "also installing the dependency ‘RcppEigen’\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  There are binary versions available but the source versions are later:\n",
      "             binary    source needs_compilation\n",
      "RcppEigen 0.3.3.9.1 0.3.3.9.2              TRUE\n",
      "lme4         1.1-28    1.1-29              TRUE\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "installing the source packages ‘RcppEigen’, ‘lme4’\n",
      "\n",
      "\n",
      "Warning message in install.packages(\"lme4\"):\n",
      "“installation of package ‘RcppEigen’ had non-zero exit status”\n",
      "Warning message in install.packages(\"lme4\"):\n",
      "“installation of package ‘lme4’ had non-zero exit status”\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in library(lme4): there is no package called ‘lme4’\n",
     "output_type": "error",
     "traceback": [
      "Error in library(lme4): there is no package called ‘lme4’\nTraceback:\n",
      "1. library(lme4)"
     ]
    }
   ],
   "source": [
    "install.packages(\"lme4\")\n",
    "library(lme4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZJns7xr41nW"
   },
   "source": [
    "Now fit a mixed effects model that includes the same predictors as the linear model above, as well as random intercepts for `Sub_ID` (i.e., cases where subject ID shifts the RT mean). Use `summary()` to look at the model output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "executionInfo": {
     "elapsed": 899,
     "status": "ok",
     "timestamp": 1615950778119,
     "user": {
      "displayName": "Patience Stevens",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi-_9ZqhIFhAv1oMehJNvNuIKSTyrFQHzjxQKhx=s64",
      "userId": "01994571539255174942"
     },
     "user_tz": 240
    },
    "id": "8kjwT0je57N7",
    "outputId": "6f4974ab-621d-4608-f3bf-113735ede739"
   },
   "outputs": [],
   "source": [
    "mixedeff <- lmer(D_RT ~ Log_Freq_HAL * Length + (1 | Sub_ID), data = lexdat)\n",
    "summary(mixedeff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vfb_ovk7JFGt"
   },
   "source": [
    "---\n",
    "## 3. Model assessment (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7B1Ux6RHGjy"
   },
   "source": [
    "Compare the three t-values for the fixed effects and the mixed effects models. How do they differ, and why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCi5gYOeHo6m"
   },
   "source": [
    "> *Write your response here* \n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hukKG1AbGqXM"
   },
   "source": [
    "Use the Aikeke Information Criterion (AIC) to compare these two models. Which one is better? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "executionInfo": {
     "elapsed": 267,
     "status": "ok",
     "timestamp": 1615949607837,
     "user": {
      "displayName": "Patience Stevens",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi-_9ZqhIFhAv1oMehJNvNuIKSTyrFQHzjxQKhx=s64",
      "userId": "01994571539255174942"
     },
     "user_tz": 240
    },
    "id": "KMDg8qb5FhJz",
    "outputId": "a148b06b-ec96-41e3-d13d-a439acbdf6d7"
   },
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE\n",
    "AIC(linearmod)\n",
    "AIC(mixedeff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4oTfsYmIvYt"
   },
   "source": [
    "> Generally, a lower AIC is better. In this case, I was not able to compare the values. \n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ARF2PF2yLXkZ"
   },
   "source": [
    "---\n",
    "##  4. Reflection (1 point)\n",
    "\n",
    "What other random effects could be controlled for in this data set? \n",
    "\n",
    "> Trial number could be controlled in this data set given that there is no change due to an effect on the reaction times.\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4MPECMmZXqe"
   },
   "source": [
    "**DUE:** 5pm EST, March 25, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9GUofXN4BVy"
   },
   "source": [
    "**IMPORTANT** Did you collaborate with anyone on this assignment? If so, list their names here. \n",
    "> *Someone's Name*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Homework6_solutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
